import numpy as np
import torch
import matplotlib.pyplot as plt



days = 32
discretization = 4
obs_per_day = 1
nobs = days * obs_per_day
MAGI_niter = 15001
N = 100000.
X = np.arange(0, days, 1. / (obs_per_day * discretization))
i0 = 50
e0 = 100
T = 2
parameter_value = [1.8, 0.1, 0.1, 0.05]
std = [1., 0.02, 0, 0.025]


tmp_2 = np.linspace(0, 2 * T * np.pi, discretization * days)
true_re = parameter_value[0] - std[0] * np.cos(tmp_2)
true_ve = parameter_value[1]- std[1] * np.cos(tmp_2)
true_vi = parameter_value[2]
true_pd = parameter_value[3] + std[3] * np.cos(tmp_2)
theta_true = np.vstack([true_re, true_ve, true_pd]).T


all_beta = np.zeros((100, days * discretization))
all_ve = np.zeros((100, days * discretization))
all_pd = np.zeros((100, days * discretization))
all_vi = np.zeros(100)
all_xinit = np.zeros((100, 4))
for i in range(100):
    file = np.load('G:/TVMAGI-' + str(discretization) + '/beta_'+str(i)+'-dis=' + str(discretization) + '.npy')
    all_beta[i] = file

for i in range(100):
    file = np.load('G:/TVMAGI-' + str(discretization) + '/ve_'+str(i)+'-dis=' + str(discretization) + '.npy')
    all_ve[i] = file  
    
for i in range(100):
    file = np.load('G:/TVMAGI-' + str(discretization) + '/pd_'+str(i)+'-dis=' + str(discretization) + '.npy')
    all_pd[i] = file  

for i in range(100):
    file = np.load('G:/TVMAGI-' + str(discretization) + '/vi_'+str(i)+'-dis=' + str(discretization) + '.npy')
    all_vi[i] = file 

for i in range(100):
    file = np.load('G:/TVMAGI-' + str(discretization) + '/xinit_'+str(i)+'-dis=' + str(discretization) + '.npy')
    all_xinit[i] = file
RMSE_beta = np.sqrt(np.mean(np.square(all_beta - true_re), axis=0))
print(np.mean(RMSE_beta), np.std(RMSE_beta))
RMSE_ve = np.sqrt(np.mean(np.square(all_ve - true_ve), axis=0))
print(np.mean(RMSE_ve), np.std(RMSE_ve))
RMSE_vi = np.abs(all_vi - true_vi)
print(np.mean(RMSE_vi), np.std(RMSE_vi))
RMSE_pd = np.sqrt(np.mean(np.square(all_pd / 4 - true_pd), axis=0))
print(np.mean(RMSE_pd), np.std(RMSE_pd))




 


%matplotlib inline
import matplotlib # 注意这个也要import一次
import matplotlib.pyplot as plt
from IPython.core.pylabtools import figsize # import figsize
#figsize(12.5, 4) # 设置 figsize
plt.rcParams['savefig.dpi'] = 300 #图片像素
plt.rcParams['figure.dpi'] = 300 #分辨率

figsize(10, 2)
plt.subplots_adjust(wspace =0, hspace =0)
ax1 = plt.subplot(1, 3, 1) # 两行一列，位置是1的子图
lower_95 = np.percentile(all_beta, 97.5, axis=0)
upper_95 = np.percentile(all_beta, 2.5, axis=0)
x = np.arange(0, 32, 1 / discretization)
plt.fill_between(x, lower_95, upper_95, color='grey', alpha = 0.4, label='95% interval')
plt.plot(x, np.mean(all_beta, axis=0), label='Mean')
plt.plot(x, true_re, label='True')
plt.title(r'$\beta$')
plt.grid()
plt.legend(bbox_to_anchor=(2.3, -0.1), fontsize=12, ncol=4)

ax2 = plt.subplot(1, 3, 2)
lower_95 = np.percentile(all_ve, 97.5, axis=0)
upper_95 = np.percentile(all_ve, 2.5, axis=0)
plt.fill_between(x, lower_95, upper_95, color='grey', alpha = 0.4)
plt.plot(x, np.mean(all_ve, axis=0))
plt.plot(x, true_ve)
plt.grid()
plt.title(r'$v^e$')

ax3 = plt.subplot(1, 3, 3)
lower_95 = np.percentile(all_pd, 97.5, axis=0)
upper_95 = np.percentile(all_pd, 2.5, axis=0)
plt.fill_between(x, lower_95/ 4, upper_95/ 4, color='grey', alpha = 0.4)
plt.plot(x, np.mean(all_pd, axis=0)/ 4)
plt.plot(x, true_pd)
plt.title(r'$p^d$')
plt.grid()





yobs = np.exp(np.load('G:/TVMAGI-2/observations.npy')[1])
figsize(10, 2)
plt.subplots_adjust(wspace =0, hspace =0)
ax1 = plt.subplot(1, 4, 1) # 两行一列，位置是1的子图
lower_95 = np.percentile(all_reconstructed_x[:,:, 0], 97.5, axis=0)
upper_95 = np.percentile(all_reconstructed_x[:,:, 0], 2.5, axis=0)
x = np.arange(0, 32, 0.001)
plt.yticks(np.array([20000, 40000, 60000, 80000, 100000]), ['2e4', '4e4', '6e4', '8e4', '1e5'])
plt.fill_between(x, lower_95, upper_95, color='grey', alpha = 0.4, label='95% interval')
plt.plot(true_x[:, 0], label='True')
plt.plot(x, np.mean(all_reconstructed_x[:,:, 0], axis=0), label='Mean of TVMAGI')
plt.scatter(np.arange(0, 32,1), yobs[:, 0], s = 1, color='black', label='Sample observation', zorder=100)
plt.grid()
plt.title(r'$S$')
plt.legend(bbox_to_anchor=(3.8, -0.1), fontsize=12, ncol=4)

ax2 = plt.subplot(1, 4, 2)
lower_95 = np.percentile(all_reconstructed_x[:,:, 1], 97.5, axis=0)
upper_95 = np.percentile(all_reconstructed_x[:,:, 1], 2.5, axis=0)
plt.yticks(np.array([10000, 20000, 30000, 40000, 50000]), ['1e4', '2e4', '3e4', '4e4', '5e4'])
plt.fill_between(x, lower_95, upper_95, color='grey', alpha = 0.4)
plt.plot(true_x[:, 1])
plt.plot(x, np.mean(all_reconstructed_x[:,:, 1], axis=0))
plt.scatter(np.arange(0, 32, 1), yobs[:, 1], s = 1, color='black', label='Sample observation', zorder=100)
plt.grid()
plt.title(r'$E$')


ax3 = plt.subplot(1, 4, 3)
lower_95 = np.percentile(all_reconstructed_x[:,:, 2], 97.5, axis=0)
upper_95 = np.percentile(all_reconstructed_x[:,:, 2], 2.5, axis=0)
plt.fill_between(x, lower_95, upper_95, color='grey', alpha = 0.4)
plt.yticks(np.array([10000, 20000, 30000]), ['1e4', '2e4', '3e4'])
plt.plot(true_x[:, 2])
plt.plot(x, np.mean(all_reconstructed_x[:,:, 2], axis=0))
plt.scatter(np.arange(0, 32, 1), yobs[:, 2], s = 1, color='black', label='Sample observation', zorder=100)
plt.grid()
plt.title(r'$I$')


ax4= plt.subplot(1, 4, 4)
lower_95 = np.percentile(all_reconstructed_x[:,:, 3], 97.5, axis=0)
upper_95 = np.percentile(all_reconstructed_x[:,:, 3], 2.5, axis=0)
# plt.yticks(np.array([250,500,750,1000,1250,1500]))
plt.fill_between(x, lower_95/4, upper_95/4, color='grey', alpha = 0.4)
plt.plot(true_x[:, 3])
plt.plot(x, np.mean(all_reconstructed_x[:,:, 3], axis=0)/4)
plt.scatter(np.arange(0, 32, 1), yobs[:, 3], s = 1, color='black', label='Sample observation', zorder=100)
plt.grid()
plt.title(r'$D$')

RMSE_S = np.zeros(100)
RMSE_E = np.zeros(100)
RMSE_I = np.zeros(100)
RMSE_D = np.zeros(100)

for i in range(100):
    RMSE_S[i] = np.sqrt(np.mean(np.square(all_reconstructed_x[i, ::1000, 0] - true_x[:, 0])))
    RMSE_E[i] = np.sqrt(np.mean(np.square(all_reconstructed_x[i, ::1000, 1] - true_x[:, 1])))
    RMSE_I[i] = np.sqrt(np.mean(np.square(all_reconstructed_x[i, ::1000, 2] - true_x[:, 2])))
    RMSE_D[i] = np.sqrt(np.mean(np.square(all_reconstructed_x[i, ::1000, 3] / 4 - true_x[:, 3])))
    
print(np.mean(RMSE_S), np.std(RMSE_S))
print(np.mean(RMSE_E), np.std(RMSE_E))
print(np.mean(RMSE_I), np.std(RMSE_I))
print(np.mean(RMSE_D), np.std(RMSE_D))






import pickle

def MaternKernel(d, phi_1, phi_2, nu=2.5):
    """
    construct a kernel given time points and hyper parameters
    """
    if nu == 2.5:  
        a = np.square(phi_1) * (
                1. + np.sqrt(5) * d / phi_2 + 5. * np.square(d) / (3. * np.square(phi_2))) * np.exp(
            -np.sqrt(5) * d / phi_2)
        return a
    else:
        a = np.square(phi_1) * (1. + np.sqrt(3) * d / phi_2) * np.exp(-np.sqrt(3) * d / phi_2)       
        return a

def GPinterp(x, y, phi_1, phi_2, inv_cov, days=32, obs_per_day=1):
    x_obs = np.arange(0, 32, 1 / discretization)
    return y.T.dot(inv_cov).dot(MaternKernel(np.abs(x_obs - x), phi_1, phi_2, nu=2.5))
    

def recover_data(beta, ve, pd, vi, state0, days=32, obs_per_day=1, discretization = 1, linspace=1000, mode='Linear', hyper=None):
    """
    params: parameter: [beta, ve, vi, pd]
    """
    # check input
    # [ S, E, I, D, cfr0]
    global d_matrix
    freq = 1. / discretization
    nFull = int(days * obs_per_day)
    step_size = 1. / (linspace * obs_per_day)
    state_ls = np.ones((nFull * linspace, 4))
    state_ls[0][0] = state0[0]
    state_ls[0][1] = state0[1]
    state_ls[0][2] = state0[2]
    state_ls[0][3] = state0[3]
    # Use linear interpolation for theta
    if mode == 'Linear': 
        x_initial = np.linspace(0, 1000, beta.shape[0])
        x_interp = np.linspace(0, 1000, 32000)
        beta_interp = np.interp(x_interp, x_initial, beta)
        ve_interp = np.interp(x_interp, x_initial, ve)
        pd_interp = np.interp(x_interp, x_initial, pd)
    # Use Gaussian interpolation for theta    
    elif mode == 'Gaussian':
        beta_interp = np.zeros(32000)
        ve_interp = np.zeros(32000)
        pd_interp = np.zeros(32000)
        beta_inv_cov = np.linalg.inv(MaternKernel(d_matrix, hyper[0][0], hyper[0][1]))
        ve_inv_cov = np.linalg.inv(MaternKernel(d_matrix, hyper[1][0], hyper[1][1]))
        pd_inv_cov = np.linalg.inv(MaternKernel(d_matrix, hyper[2][0], hyper[2][1]))
        for i in range(32000):
            beta_interp[i] = GPinterp(i / 1000, beta, hyper[0][0], hyper[0][1], beta_inv_cov, discretization)
            ve_interp[i] = GPinterp(i / 1000, ve, hyper[1][0], hyper[1][1], ve_inv_cov, discretization)
            pd_interp[i] = GPinterp(i / 1000, pd, hyper[2][0], hyper[2][1], pd_inv_cov, discretization)
    else:
        raise ValueError
        
        
    for i in range(1, linspace * nFull):
        index = i - 1
        state_ls[i][0] = state_ls[i - 1][0] - step_size * beta_interp[index] * state_ls[i - 1][2] * state_ls[i - 1][0] / N
        state_ls[i][1] = state_ls[i - 1][1] + step_size * beta_interp[index] * state_ls[i - 1][2] * state_ls[i - 1][0] / N - step_size * ve_interp[index] * state_ls[i - 1][1]
        state_ls[i][2] = state_ls[i - 1][2] + step_size * ve_interp[index] * state_ls[i - 1][1] - step_size * state_ls[i - 1][2] * vi
        state_ls[i][3] = state_ls[i - 1][3] + step_size * state_ls[i - 1][2] * vi * pd_interp[index]
#     states = state_ls[::int(linspace / discretization)]
    return state_ls

n_points = days * discretization
d_matrix = np.zeros((n_points, n_points))
for i in range(n_points):
    for j in range(n_points):
        if i > j:
            d_matrix[i][j] = (i - j) / (obs_per_day * discretization)
        else:
            d_matrix[i][j] = (j - i) / (obs_per_day * discretization)    
all_reconstructed_x = np.zeros((100, 32000, 4))
for i in range(100):
    print(i)
    file = open('G:/TVMAGI-' + str(discretization) + '/hyper_' + str(i) + '-dis=' + str(discretization) + '.txt','rb')
    hyper_ls = pickle.load(file)
    all_reconstructed_x[i] = recover_data(all_beta[i], all_ve[i], all_pd[i], all_vi[i], np.exp(all_xinit[i]), mode='Gaussian', hyper=hyper_ls)
